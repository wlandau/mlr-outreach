
@article{Bischl_2016,
  author  = {Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones},
  title   = {mlr: Machine Learning in R},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {170},
  pages   = {1-5},
  url     = {http://jmlr.org/papers/v17/15-066.html}
}

@article{Bischl_2017a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.03373},
  primaryClass = {stat},
  title = {{{mlrMBO}}: {{A Modular Framework}} for {{Model}}-{{Based Optimization}} of {{Expensive Black}}-{{Box Functions}}},
  shorttitle = {{{mlrMBO}}},
  journal = {arXiv:1703.03373 [stat]},
  author = {Bischl, Bernd and Richter, Jakob and Bossek, Jakob and Horn, Daniel and Thomas, Janek and Lang, Michel},
  year = {2017},
  keywords = {Statistics - Machine Learning}
}

@inproceedings{ponweiser_multiobjective_2008,
  title = {Multiobjective {{Optimization}} on a {{Limited Budget}} of {{Evaluations Using Model}}-{{Assisted}} $\mathcal{S}$-{{Metric Selection}}},
  isbn = {978-3-540-87699-1 978-3-540-87700-4},
  url = {https://link.springer.com/chapter/10.1007/978-3-540-87700-4_78},
  doi = {10.1007/978-3-540-87700-4_78},
  abstract = {Real-world optimization problems often require the consideration of multiple contradicting objectives. These multiobjective problems are even more challenging when facing a limited budget of evaluations due to expensive experiments or simulations. In these cases, a specific class of multiobjective optimization algorithms (MOOA) has to be applied. This paper provides a review of contemporary multiobjective approaches based on the singleobjective meta-model-assisted ’Efficient Global Optimization’ (EGO) procedure and describes their main concepts. Additionally, a new EGO-based MOOA is introduced, which utilizes the S$\backslash$mathcal\{S\}-metric or hypervolume contribution to decide which solution is evaluated next. A benchmark on recently proposed test functions is performed allowing a budget of 130 evaluations. The results point out that the maximization of the hypervolume contribution within a real multiobjective optimization is superior to straightforward adaptations of EGO making our new approach capable of approximating the Pareto front of common problems within the allowed budget of evaluations.},
  eventtitle = {International Conference on Parallel Problem Solving from Nature},
  timestamp = {2017-10-26T10:14:11Z},
  langid = {english},
  booktitle = {Parallel {{Problem Solving}} from {{Nature}} – {{PPSN X}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer, Berlin, Heidelberg}},
  author = {Ponweiser, Wolfgang and Wagner, Tobias and Biermann, Dirk and Vincze, Markus},
  urldate = {2017-10-26},
  date = {2008-09-13},
  pages = {784--794},
  file = {Full Text PDF:/home/richter/.zotero/zotero/e1q03h92.default/zotero/storage/EQS33UHK/Ponweiser et al. - 2008 - Multiobjective Optimization on a Limited Budget of.pdf:application/pdf;Snapshot:/home/richter/.zotero/zotero/e1q03h92.default/zotero/storage/8BUJ5XST/978-3-540-87700-4_78.html:text/html}
}

@article{knowles_parego:_2006,
  title = {{{ParEGO}}: A Hybrid Algorithm with on-Line Landscape Approximation for Expensive Multiobjective Optimization Problems},
  volume = {10},
  issn = {1089-778X},
  doi = {10.1109/TEVC.2005.851274},
  shorttitle = {{{ParEGO}}},
  abstract = {This paper concerns multiobjective optimization in scenarios where each solution evaluation is financially and/or temporally expensive. We make use of nine relatively low-dimensional, nonpathological, real-valued functions, such as arise in many applications, and assess the performance of two algorithms after just 100 and 250 (or 260) function evaluations. The results show that NSGA-II, a popular multiobjective evolutionary algorithm, performs well compared with random search, even within the restricted number of evaluations used. A significantly better performance (particularly, in the worst case) is, however, achieved on our test set by an algorithm proposed herein-ParEGO-which is an extension of the single-objective efficient global optimization (EGO) algorithm of Jones et al. ParEGO uses a design-of-experiments inspired initialization procedure and learns a Gaussian processes model of the search landscape, which is updated after every function evaluation. Overall, ParEGO exhibits a promising performance for multiobjective optimization problems where evaluations are expensive or otherwise restricted in number.},
  timestamp = {2017-10-26T09:59:00Z},
  number = {1},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  author = {Knowles, J.},
  date = {2006-02},
  pages = {50--66},
  keywords = {Approximation algorithms,Design and analysis of computer experiments (DACE),Design of experiments,design-of-experiments,efficient global optimization (EGO),evolutionary computation,expensive black-box functions,expensive multiobjective optimization problems,Gaussian Processes,Gaussian processes model,Instruments,Kriging,landscape approximation,metamodels,multiobjective optimization,nondominated sorting genetic algorithm II (NSGA-II),NSGA-II multiobjective evolutionary algorithm,online landscape approximation,optimisation,Optimization methods,ParEGO,Pareto analysis,Pareto optima,Pareto optimization,performance assessment,Performance evaluation,response surfaces,search landscape,Search methods,search problems,single-objective efficient global optimization algorithm,Testing,test suites},
  file = {IEEE Xplore Full Text PDF:/home/richter/.zotero/zotero/e1q03h92.default/zotero/storage/KV8II98Z/Knowles - 2006 - ParEGO a hybrid algorithm with on-line landscape .pdf:application/pdf;IEEE Xplore Abstract Record:/home/richter/.zotero/zotero/e1q03h92.default/zotero/storage/6JZ9RT9V/1583627.html:text/html}
}
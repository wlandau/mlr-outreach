<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>mlr3</title>
    <meta charset="utf-8" />
    <meta name="author" content="Michel Lang, Bernd Bischl, Jakob Richter, Patrick Schratz, Martin Binder" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/robot-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">



class: inverse

&lt;br&gt;

.center[
# mlr3

## _Modern machine learning in R_
]

.center[
### Michel Lang, Bernd Bischl, Jakob Richter, Patrick Schratz, Martin Binder
]
.center[
&lt;img src="https://www.statistik.tu-dortmund.de/fileadmin/_processed_/8/b/csm_lang_0553e84b11.jpg" height="150" /&gt;&lt;img src="https://www.compstat.statistik.uni-muenchen.de/images/bernd.jpg" height="150" /&gt;&lt;img src="https://www.statistik.tu-dortmund.de/fileadmin/_processed_/0/7/csm_jakob_richter_37967a7cae.jpg" height="150" /&gt;&lt;img src="https://lh5.googleusercontent.com/-J_qwCXEdtmA/AAAAAAAAAAI/AAAAAAAAAis/LLPrAyjEjD0/photo.jpg" height="150" /&gt;&lt;img src="https://avatars0.githubusercontent.com/u/15801081?s=400&amp;v=4" height="150" /&gt;
]

.center.font150[
[**bit.ly/2LMwE7W**](https://bit.ly/2LMwE7W)
]
---

## mlr-v2

Meta framework for everything machine learning (evaluation, visualization, tuning, wrapping, bagging, ...)

#### Monolithic package

* Interfaces &gt; 150 learners  
  <i class="fas  fa-arrow-right "></i> Dependencies (direct / recursive): 119 / 1436  
  <i class="fas  fa-arrow-right "></i> Unit tests take &gt; 2h  
  <i class="fas  fa-arrow-right "></i> Continuous integration split into multiple stages, rather unstable  
  
* Most unit tests disabled for CRAN to comply to their policy  
  <i class="fas  fa-arrow-right "></i> No tests in reverse dependency checks on CRAN  
  <i class="fas  fa-arrow-right "></i> Package developers changed their API and (unknowingly) broke mlr  
  
* High barrier for new contributors

---

## mlr-v2

#### Missing OO

* S3 reaches its limitations in larger software projects

* Many different container types for results with awkward accessors: `getBMRAggrPerformances()`

* `NAMESPACE` has &gt; 1200 lines, &gt; 440 exported functions and objects

* Wrappers (pipelines) hard to customize and to work with

#### Further Design Issues

* Only works on in-memory data

* No nested parallelization

---
class: inverse, center, middle

# mlr3

---
## mlr3

* Overcome limitations of S3 with the help of **R6**
  * Truly object-oriented (OO): data and methods together
  * Inheritance
  * Reference semantics
  
* Embrace **data.table**, both for arguments and for internal data structures
  * Fast operations for tabular data
  * Better support for list columns to arrange complex objects in a tabular structure
  * Reference semantics
  
* Be **light on dependencies**. Direct and recursive dependencies:
  * `R6`, `data.table`, `Metrics`, `lgr`
  * Some self-maintained packages (`backports`, `checkmate`, ...)

---
class: inverse, center, middle

# Building Blocks

---

## Building Blocks
&lt;img src="ml_abstraction.png" width="3312" /&gt;

---

## Tasks

.code100[
<i class="fas  fa-arrow-right "></i> Create your own task

```r
TaskClassif$new("iris", iris, target = "Species")
```

```
## &lt;TaskClassif:iris&gt; (150 x 5)
## Target: Species
## Properties: multiclass
## Features (4):
## * dbl (4): Petal.Length, Petal.Width, Sepal.Length, Sepal.Width
```
    
<i class="fas  fa-arrow-right "></i> Retrieve a predefined task from the task dictionary


```r
mlr_tasks
```

```
## &lt;DictionaryTask&gt; with 9 stored values
## Keys: boston_housing, german_credit, iris, mtcars, pima, sonar,
##   spam, wine, zoo
```

```r
task = mlr_tasks$get("iris")
```
  ]
---
## Learner

<i class="fas  fa-arrow-right "></i> Retrieve a predefined learner from the learner dictionary

.code100[
 
 ```r
 mlr_learners
 ```
 
 ```
 ## &lt;DictionaryLearner&gt; with 21 stored values
 ## Keys: classif.debug, classif.featureless, classif.glmnet,
 ##   classif.kknn, classif.lda, classif.log_reg, classif.naive_bayes,
 ##   classif.qda, classif.ranger, classif.rpart, classif.svm,
 ##   classif.xgboost, regr.featureless, regr.glmnet, regr.kknn,
 ##   regr.km, regr.lm, regr.ranger, regr.rpart, regr.svm,
 ##   regr.xgboost
 ```
]
---

## Learner

<i class="fas  fa-arrow-right "></i> Retrieve a predefined learner from the learner dictionary

.code100[
 
 ```r
 learner = mlr_learners$get("classif.rpart")
 print(learner)
 ```
 
 ```
 ## &lt;LearnerClassifRpart:classif.rpart&gt;
 ## Model: -
 ## Parameters: xval=0
 ## Packages: rpart
 ## Predict Type: response
 ## Feature types: logical, integer, numeric, character, factor,
 ##   ordered
 ## Properties: importance, missings, multiclass, selected_features,
 ##   twoclass, weights
 ```
]
---
## Learner

<i class="fas  fa-arrow-right "></i> Querying and setting hyperparameters
.code100[

```r
# query
learner$param_set
```

```
## ParamSet: 
##              id    class lower upper levels default value
## 1:     minsplit ParamInt     1   Inf             20      
## 2:           cp ParamDbl     0     1           0.01      
## 3:   maxcompete ParamInt     0   Inf              4      
## 4: maxsurrogate ParamInt     0   Inf              5      
## 5:     maxdepth ParamInt     1    30             30      
## 6:         xval ParamInt     0   Inf             10     0
```

```r
# set
learner$param_set$values = list(xval = 0, cp = 0.1)
```
    ]
    
---

## Learner

<i class="fas  fa-arrow-right "></i> Training
.code100[

```r
task = mlr_tasks$get("iris")
learner$train(task, row_ids = 1:120)
```
]
NB: This changes the learner in-place, model is now stored inside the learner.

---
## Learner

<i class="fas  fa-arrow-right "></i> Accessing the learner model
.code90[

```r
learner$model
```

```
## n= 120 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
## 1) root 120 70 setosa (0.41666667 0.41666667 0.16666667)  
##   2) Petal.Length&lt; 2.45 50  0 setosa (1.00000000 0.00000000 0.00000000) *
##   3) Petal.Length&gt;=2.45 70 20 versicolor (0.00000000 0.71428571 0.28571429)  
##     6) Petal.Length&lt; 4.95 49  1 versicolor (0.00000000 0.97959184 0.02040816) *
##     7) Petal.Length&gt;=4.95 21  2 virginica (0.00000000 0.09523810 0.90476190) *
```
]

<i class="fas  fa-arrow-right "></i> Variable importance
.code100[

```r
learner$importance()
```

```
## Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
##     69.42177     65.04211     41.85520     29.11840
```
]

---
## Predictions

<i class="fas  fa-arrow-right "></i> Generate predictions
.code100[

```r
p = learner$predict(task, row_ids = 121:150)
head(as.data.table(p), 3)
```

```
##    row_id     truth   response
## 1:    121 virginica  virginica
## 2:    122 virginica versicolor
## 3:    123 virginica  virginica
```
]

<i class="fas  fa-arrow-right "></i> Confusion matrix
.code100[

```r
p$confusion
```

```
##             truth
## response     setosa versicolor virginica
##   setosa          0          0         0
##   versicolor      0          0         5
##   virginica       0          0        25
```
]

---

## Performance Assessment
<i class="fas  fa-arrow-right "></i> Retrieve a predefined measure from the measure dictionary
.code100[

```r
measure = mlr_measures$get("classif.acc")
measure
```

```
## &lt;MeasureClassifACC:classif.acc&gt;
## Packages: Metrics
## Range: [0, 1]
## Minimize: FALSE
## Properties: -
## Predict type: response
```
]

<i class="fas  fa-arrow-right "></i> Calculate performance
.code100[

```r
p$score(c("classif.acc", "time_train"))
```

```
## classif.acc  time_train 
##   0.8333333   0.0000000
```
]

---
class: inverse, center, middle

# Rinse and Repeat

---
## Resample

.code100[
<i class="fas  fa-arrow-right "></i> Resampling Object


```r
cv3 = mlr_resamplings$get("cv", param_vals = list(folds = 3))
```

Splits into train/test are efficiently stored and can be accessed with `$train_set(i)` and `$test_set(i)`.

<i class="fas  fa-arrow-right "></i> Resample a regression tree on the Boston housing data using a 3-fold CV


```r
# string -&gt; object conversion via dictionary
rr = resample("boston_housing", "regr.rpart", cv3)
```

<i class="fas  fa-arrow-right "></i> Aggregated performance


```r
rr$aggregate("regr.mse")
```

```
## regr.mse 
## 2.973355
```
]

---

## Benchmarking

.code90[
<i class="fas  fa-arrow-right "></i> Exhaustive grid design

```r
grid = expand_grid(
    tasks = "iris",
    learners = c("classif.featureless", "classif.rpart"),
    resamplings = "cv3"
)
bmr = benchmark(grid, ctrl = list(store_models = TRUE))
aggr = bmr$aggregate("classif.acc")
aggr[, 2:6]
```

```
##     resample_result task_id          learner_id resampling_id classif.acc
## 1: &lt;ResampleResult&gt;    iris classif.featureless           cv3   0.2866667
## 2: &lt;ResampleResult&gt;    iris       classif.rpart           cv3   0.9466667
```
]

---

## Benchmarking

.code100[
<i class="fas  fa-arrow-right "></i> Retrieving objects


```r
aggr$resample_result[[2]]$prediction$confusion
```

```
##             truth
## response     setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         45         3
##   virginica       0          5        47
```
]

---

## Tuning

* Algorithms: _Grid Search_, _Random Search_, _Simulated Annealing_
* In process: _Bayesian Optimization_, _iterated F-racing_, _EAs_
* Budget via class `Terminator`: iterations, performance, runtime, real time
* Nested resampling via class `AutoTuner`

```r
ps = ParamSet$new(list(
  ParamInt$new("num.trees", lower = 50, upper = 500),
  ParamInt$new("mtry", lower = 1, upper = 5)
))

at = AutoTuner$new(
  learner = "classif.ranger",
  resampling = "cv3", # inner resampling
  measures = "classif.acc",
  param_set = ps,
  terminator = TerminatorEvaluations$new(10),
  tuner = TunerRandomSearch
)

resample(
  task = "spam",
  learner = at,
  resampling = "holdout" # outer resampling
)
```


---

class: inverse, center, middle

# Behind the Curtain

---

## Internal Data Structure

All result objects (`resample()`, `benchmark()`, tuning, ...) share the same structure:
.code90[

```r
as.data.table(rr)
```

```
##               learner       prediction       task     resampling iteration
## 1: &lt;LearnerRegrRpart&gt; &lt;PredictionRegr&gt; &lt;TaskRegr&gt; &lt;ResamplingCV&gt;         1
## 2: &lt;LearnerRegrRpart&gt; &lt;PredictionRegr&gt; &lt;TaskRegr&gt; &lt;ResamplingCV&gt;         2
## 3: &lt;LearnerRegrRpart&gt; &lt;PredictionRegr&gt; &lt;TaskRegr&gt; &lt;ResamplingCV&gt;         3
```
]

#### Combining R6 and data.table
* Not the objects are stored, but pointers to them

* Inexpensive to work on:
  * `rbind()`: copying R6 objects &amp;wedgeq; copying pointers
  * `cbind()`: `data.table()` over-allocates columns, no copies
  * `[i, ]`: lookup row (possibly hashed), create a list of pointers
  * `[, j]`: direct access to list element


---

## Control of Execution

.code100[
<i class="fas  fa-arrow-right "></i> Parallelization

```r
future::plan("multicore")
benchmark(grid)
```
* runs each resampling iteration as a job&lt;br/&gt;
* also allows nested resampling (although not needed here)


<i class="fas  fa-arrow-right "></i>  Encapsulation


```r
ctrl = mlr_control(encapsulate_train = "callr")
benchmark(grid, ctrl = ctrl)
```
* Spawns a separate R process to train the learner
* Learner may segfault without tearing down the master session
* Logs are captured
* Possibility to have a fallback learner to create predictions

]
---

## Out-of-memory Data

* Task stores data in a `DataBackend`:
    * `DataBackendDataTable`: Default backend for dense data (in-memory)
    * `DataBackendMatrix`: Backend for sparse numerical data (in-memory)
    * `DataBackendDplyr`: Backend for many DBMS (out-of-memory).
    * `DataBackendCbind`: Combine backends in a `cbind()` fashion (virtual)
    * `DataBackendRbind`: Combine backends in a `rbind()` fashion (virtual)
    
* Backends are immutable
    * Filtering rows or selecting columns just modifies the "view" on the data
    * Multiple tasks can share the same backend
    
* Example: Interface a read-only MariaDB with `DataBackendDplyr`, add generated features via `DataBackendDataTable`

---

## Current state

* Preview release uploaded to CRAN

* Started extension packages:
  * `mlr3db` for additional backends
  * `mlr3pipelines` to create workflows
  * `mlr3learners` for recommended learners
  * `mlr3tuning` for tuning
  * `mlr3survival` for survival analysis
  * `mlr3viz` for visualizations
* Planned extensions:
  * forecasting
  * spatio-temporal analysis
  * deep learning with keras
  * connector to Apache Spark

&lt;div align="center" style="font-size: 140%"&gt;
Want to contribute?&lt;br/&gt;
&lt;a href="https://mlr3.mlr-org.com"&gt;mlr3.mlr-org.com&lt;/a&gt;
&lt;/div&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
